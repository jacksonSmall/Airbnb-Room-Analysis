{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94251124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf6f6045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4244 entries, 0 to 4243\n",
      "Data columns (total 22 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   Marital status                       4244 non-null   object \n",
      " 1   Application mode                     4244 non-null   object \n",
      " 2   Course                               4244 non-null   object \n",
      " 3   Previous qualification (grade)       4244 non-null   float64\n",
      " 4   Mother's qualification               4244 non-null   object \n",
      " 5   Father's qualification               4244 non-null   object \n",
      " 6   Mother's occupation                  4244 non-null   object \n",
      " 7   Father's occupation                  4244 non-null   object \n",
      " 8   Admission grade                      4244 non-null   float64\n",
      " 9   Displaced                            4244 non-null   object \n",
      " 10  Educational special needs            4244 non-null   object \n",
      " 11  Debtor                               4244 non-null   object \n",
      " 12  Tuition fees up to date              4244 non-null   object \n",
      " 13  Gender                               4244 non-null   object \n",
      " 14  Scholarship holder                   4244 non-null   object \n",
      " 15  Age at enrollment                    4244 non-null   int64  \n",
      " 16  International                        4244 non-null   object \n",
      " 17  Curricular units 1st sem (credited)  4244 non-null   int64  \n",
      " 18  Curricular units 1st sem (enrolled)  4244 non-null   int64  \n",
      " 19  Curricular units 1st sem (approved)  4244 non-null   int64  \n",
      " 20  Curricular units 1st sem (grade)     4244 non-null   float64\n",
      " 21  Target                               4244 non-null   object \n",
      "dtypes: float64(3), int64(4), object(15)\n",
      "memory usage: 729.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Importing the csv file\n",
    "df_reduced = pd.read_csv('data_reduced.csv')\n",
    "df_reduced = df_reduced.drop(columns=['Unnamed: 0'])\n",
    "#df_reduced[\"Target\"] = df_reduced[\"Target\"].str.replace(r\"Graduate|Enrolled\",\"Non-dropout\", regex=True)\n",
    "df_reduced.head()\n",
    "df_reduced.info()\n",
    "\n",
    "# Split data into X and Y components\n",
    "X = df_reduced.drop(columns=['Target'])\n",
    "Y = df_reduced['Target']\n",
    "#Y = Y.replace({'Dropout': \"Non-graduate\", 'Enrolled': \"Non-graduate\"})\n",
    "\n",
    "# Identify column types\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "numerical_columns = X.select_dtypes(include=['number']).columns\n",
    "categorical_columns, numerical_columns\n",
    "\n",
    "# Split training and test data with stratified sampling\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1, stratify=Y)\n",
    "\n",
    "# Process the data\n",
    "preprocessors = ColumnTransformer([\n",
    "    ('num_scaler', StandardScaler(), numerical_columns),\n",
    "    ('categorical_encoder', OneHotEncoder(handle_unknown='ignore'), categorical_columns)\n",
    "    ])\n",
    "X_train_transformed = preprocessors.fit_transform(X_train)\n",
    "X_test_transformed = preprocessors.transform(X_test)\n",
    "\n",
    "# Ensure X's are dense and not sparse data type\n",
    "# This is necessary because of the OneHotEncoding \n",
    "# making more columns.\n",
    "\n",
    "X_train_transformed = (X_train_transformed.todense()).A\n",
    "X_test_transformed = (X_test_transformed.todense()).A\n",
    "\n",
    "#smote = SMOTENC(categorical_features=list(range(7,21)), random_state=0)\n",
    "#X_train_transformed,Y_train = smote.fit_resample(X_train_transformed,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd43d66",
   "metadata": {},
   "source": [
    "# Defining a voting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0dc7ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Dropout       0.82      0.68      0.74       269\n",
      "    Enrolled       0.49      0.37      0.42       153\n",
      "    Graduate       0.78      0.93      0.85       427\n",
      "\n",
      "    accuracy                           0.75       849\n",
      "   macro avg       0.70      0.66      0.67       849\n",
      "weighted avg       0.74      0.75      0.74       849\n",
      "\n",
      "Accuracy:  0.7502944640753828\n"
     ]
    }
   ],
   "source": [
    "voting = VotingClassifier(estimators=[\n",
    "    ('logistic', LogisticRegression(max_iter=1000)),\n",
    "    ('svm', SVC(probability=True)),\n",
    "    ('naive_bayes', GaussianNB())\n",
    "], voting='soft',\n",
    "                          weights=[2, 2, 1])\n",
    "\n",
    "voting.fit(X_train_transformed, Y_train)\n",
    "Y_pred = voting.predict(X_test_transformed)\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "print(\"Accuracy: \", accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c5277b",
   "metadata": {},
   "source": [
    "# Running a grid search to find optimal parameters for voting ensemble (but you can replace with your own model and parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7b2c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best weights:  {'weights': (4, 2, 1)}\n",
      "Best score:  0.7385311145135136\n",
      "Best estimator:  VotingClassifier(estimators=[('logistic', LogisticRegression(max_iter=1000)),\n",
      "                             ('svm', SVC(probability=True)),\n",
      "                             ('naive_bayes', GaussianNB())],\n",
      "                 voting='soft', weights=(4, 2, 1))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Dropout       0.81      0.70      0.75       269\n",
      "    Enrolled       0.47      0.33      0.39       153\n",
      "    Graduate       0.77      0.93      0.84       427\n",
      "\n",
      "    accuracy                           0.75       849\n",
      "   macro avg       0.69      0.65      0.66       849\n",
      "weighted avg       0.73      0.75      0.73       849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_weights = range(1, 4)\n",
    "svm_weights = range(1, 4)\n",
    "nb_weights = range(1, 4)\n",
    "\n",
    "weights_grid = []\n",
    "for i in log_weights:\n",
    "    for j in svm_weights:\n",
    "        for k in nb_weights:\n",
    "            weights_grid.append((i, j, k))\n",
    "\n",
    "# Grid search to find best value of weights for soft voting classifier\n",
    "grid = GridSearchCV(estimator=voting, param_grid={'weights': weights_grid}, cv=StratifiedKFold(n_splits=5), scoring='f1_weighted')\n",
    "grid.fit(X_train_transformed, Y_train)\n",
    "print(\"Best weights: \", grid.best_params_)\n",
    "print(\"Best score: \", grid.best_score_)\n",
    "print(\"Best estimator: \", grid.best_estimator_)\n",
    "# Fit the best estimator on the entire training set\n",
    "best_voting = grid.best_estimator_\n",
    "best_voting.fit(X_train_transformed, Y_train)\n",
    "Y_pred = best_voting.predict(X_test_transformed)\n",
    "print(classification_report(Y_test, Y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
